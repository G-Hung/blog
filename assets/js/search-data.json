{
  
    
        "post0": {
            "title": "3 basic theorems in probability",
            "content": "For a long time, I confused their relationship . When I had my statistics class, I always confused these three in my mind: . Chebyshev’s inequality [I don’t know how to pronounce :- , usually just call it CS inequality]: met it few times in my life but didn’t leave me a big impression. . Law of large number &amp; Central Limit Theorem: always use them interchangeably, but deep in my heart I remember they are different . Recently in a conversation with my friend, we talked about some hypothesis testing things [t-test], we discussed the assumptions of t-test like this: . A: yeah, you see, even the distribution shapes of these two population are different By central limit theorem, the means will follow normal distribution regardless of the shape We can still use it even the distributions are not normal B: Sure, law of large number right? As we have more samples they will converage and hence t-test is valid even the distributions are not normal A: oooo seemingly right..... . Obviously I am A, but I was hestiate for few seconds because I forgot what is law of large number and how is it related to CLT! I remember they have some subtle differences. Therefore, I revisit the materials in probability course recently to answer the difference myself, and what the hell is Chebyshev’s inequality . Chebyshev’s inequality . Recall the basic numbers for distribution, expected value and variance, one describes the central tendency, another describes the spreadness of the distribution . If the variance is small, the distribution is not that widely spread, it is less likely to get the outcome far away from the mean . In mathematical terms, it is less likely to see | X - u | &gt;= certain number, hence P( | X - u | &gt;= certain number) should be small. | . When that certain number becomes even bigger, that probability should become even smaller [less likely]. . Chebyshev’s inequality basically states this relationship using expected value and variance: . P( | X - E(X) | &gt;= a) &lt;= Var(X) / a^2 for a &gt; 0 | . The importance of this equation is that we can calculate the sample size after we specify what level of confidence and bound we want . It is also beautiful! Link expected value and variance together in one inequality regardless of distributions . Law of large number . Recall the fact that variance will decrease when n increases and take a look on Chebyshev’s inequality again! . P( | X - E(X) | &gt;= a) &lt;= Var(X) / a^2 for a &gt; 0 | . | Var(X) -&gt; 0 as n increases | . Therefore, P( | X-E(X) | &gt;= a) -&gt; 0 for a &gt; 0 | . Therefore, P( | mean(X)-E(X) | &gt;=a) -&gt; 0 | . Law of large number basically tells us the sample average will converge to expected value when n increase, basis of statistics and simulation . Central Limit Theorem . CLT tells us average of n observations of ANY r.v will follow normal, ALL distributions, no matter how complex it is as long as mean and variance are finite . Conclusion . Now rethink what each of them is doing . CS inequality tells us that the difference b/w sample and expected value is bounded LLN tells us the difference b/w sample mean and expected value is not only bounded, but converages to zero when n increases CLT tells us the sample mean not only converages, but the distribution of sample mean converages to normal distribution when n increases regardless of underlying distributions . CLT makes the biggest claim and hence is also the most famous, valuable and backbone of statistics . Recall the t-test conversation . A: yeah, you see, even the distribution shapes of these two population are different By central limit theorem, the means will follow normal distribution regardless of the shape We can still use it even the distributions are not normal B: Sure, law of large number right? As we have more samples they will converage and hence t-test is valid even the distributions are not normal ^^^This statement is not correct^^^ # sample mean does converges to expected value # but nothing to do with converging to normal distribution A: oooo seemingly right..... . Disclaimer . Some of them are not precise &amp; complete description, eg you may rmb weak/strong law of large number, reading a mathematical statistics book maybe more useful. .",
            "url": "https://g-hung.github.io/blog/statistics/2021/05/31/revisit-basic-theorem-in-probability.html",
            "relUrl": "/statistics/2021/05/31/revisit-basic-theorem-in-probability.html",
            "date": " • May 31, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "From Scripts To Prediction API",
            "content": "Medium link . This is an old article I posted in Medium, I may just provide the link without reproducing it here! . After we have the ML/DS scripts, how can others make use of the predictions? Definitely we don’t want to run the scripts ourselves and send it over the email / message. A common approach is to develop the API . This article continues from the last medium post and discusses how to build the prediction API and the importance of unit testing .",
            "url": "https://g-hung.github.io/blog/engineering/workflow/2020/08/16/from-scripts-to-predictionapi.html",
            "relUrl": "/engineering/workflow/2020/08/16/from-scripts-to-predictionapi.html",
            "date": " • Aug 16, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "From Jupyter Notebook To Scripts",
            "content": "Medium link . This is an old article I posted in Medium, I may just provide the link without reproducing it here! . This article records part of my learnings from my practicum at Manifold AI! I remember I was a big fan of Jupyter Notebook and wanted to use it for everything! . My first time to use Jupyter Notebook in work [not exploration / homework] was to try Databricks to handle some data processing works. I was amazed by the notebook style because I am not from CS background and I would love to see what is happening in every step! . But I found that those colleagues with CS background don’t prefer this way, I had no clues why. Slowly, I started to feel inconvenient too when the processing logics are more and more complex…….Well, things are still working……. . Until I worked in Manifold AI and needed to write the whole workflow, I finally found that it is much much easier &amp; more flexible to run the code by a list of commands instead of a long Notebook…… . Plus, I have the habit to write unit tests whenever possible after I experienced how painful it is when you try to refactor any non-trival codebase. . During the painful job searching period in 2020 [wtf graduated during COVID-19], I didn’t have many things to do so I summarized and wrote this up. .",
            "url": "https://g-hung.github.io/blog/engineering/workflow/2020/08/06/from-jupyter-notebook-to-scripts.html",
            "relUrl": "/engineering/workflow/2020/08/06/from-jupyter-notebook-to-scripts.html",
            "date": " • Aug 6, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Start from Hong Kong: 199X - 2019 . Yoooo! I am Geoffrey from Hong Kong, currently in California! I graduated with my BSc in Statistics from CUHK, the place that I am proud of &lt;3. . I worked in various companies in Hong Kong! I am glad to meet a lot of great leaders &amp; colleagues and learn from them. . . Move to SF Bay Area: 2019 - Now . In 2019, I moved to the Bay Area to attend the University of San Francisco’s MSDS. I enjoy the environment [maybe not the downtown :( ] and all the great people I have met in the Bay Area! Sadly, I cannot experience the “normal” social life because of COVID :( . from time to time, I have some random walks around the Bay side, walk, sit and think . MSDS and Manifold: 2019 - 2020 . I am fortunate enough to do my practium at Manifold AI and work on some open-ended research using deep learning with world class tech-leaders and hardcore engineers. This experience also changes my understandings in ML/DS and engineering in general! . . Interests . My interests are DS and engineering in general, I am particularly interested in ML/DS workflow. I honor the Three Virtues of a programmer and love to bring those virtues to ML/DS world! . Outside work and study, I have started to pick up cooking skills since 2020 [because of COVID]. I have also spent some times on Brawl Stars [hit me by #C2QRU8QQ]. Reading is also a big component of my life, I enjoy history and psychology most! I will probably include some books that impact me the most in a section of this site . For this site . I don’t think I will take aggressive approach [aka job searching] for this blog. Afterall I see there are so many blogs without updates for years after the authors found the job LOL I don’t want to be one of them and hope to sustain this blog longer. I will probably treat this as my private space and library to keep track of my thoughts and learnings. . Depending on materials, maybe I will use Chinese 中文 some times .",
          "url": "https://g-hung.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "Read/Watch/Learn",
          "content": "Sapiens: A Brief History of Humankind . I have met many people said they have read this, maybe it is too famous lol I have read it and finished the Coursera course from the same author. . The single view that impacts me most is: humans are living in both subjective and objective world. In fact, money, nation, values etc are all constructed by our minds. They are meaningless if no one believe that . . Resources: Sebastian Raschka . In short, this is the first place I will go if I need to review the topics about ML/DL. I particularly enjoy the clear &amp; easy-to-follow logic. Plus, there are many code examples! . . Resources: Full Stack Deep Learning . Cover almost everything I want to learn about ML workflow, strongly recommend if you need to worry engineering part of the ML as well . . Coursera: 史記 . 「從歷史來看，決定人生成敗的不過就是兩樣東西，第一是運氣，第二是自我要求。什麼是運氣？往大的方面來說，生在什麼時代是運氣，生在什麼國家是運氣，生在什麼家庭也是運氣。往小的說，出門左轉或右轉，接不接一個電話人生可能就不一樣，運氣對每個人就是這麼重要。但是運氣不可測也不能控制，我們所能控制的只有自我要求，如果我們真心想成為什麼樣的人，是真心不是發夢想想，就必須不斷奮鬥努力讓自己具有足夠條件，等待偶然的機會」 . 這段課文感受良多，沒有人會希望運氣不好，人品好做好準備也是會有倒楣的時候，但個人只能控制自我要求，想成為什麼境界的人就做什麼事 . . How to Fail at Almost Everything and Still Win Big . I knew Scott Adams because of his cartoons. This book shares many practical “principles” that impact me a lot, eg: . Goals are for losers; systems are for winners [the world is so random, it is hard to set the goal to become millionaire next year but we can do what millionaire will do] | Passion is useless [sad but true, no one is interested in how passionate Steve Jobs is before his success] | A combination of mediocre skills can make you surprisingly valuable [few top 10% skills maybe better than a single top 1%] | . . Atomic Habits . I found this after I read “systems are for winners” from Scott Adams’s book. If I need to summarize the whole book, below are my takes: . Find the habits you want to build and decompose until it is almost impossible to fail eg: fitness: instead of going to Gym room 4 times a week, just do at least 3 push up per day | eg: reading: instead of reading certain pages, just read at least one paragraph per day | eg: programming: instead of doing 10 Leetcode during weekend, just do the daily challenge | . | After you identify the habits, do them for 21+ days . | Don’t cultivate too many at a time | . Video: DO NOT SPLIT 不割席 . As Hong Konger, it doesn’t make sense if I tell you I have no views on what happened over the last few years :( It is sad that the conflicts will probably last for decades b/w the people and you can do nth about that. . Over these 2 years, I always have these questions in my mind: . The conflict could be resolved easily from the beginning, how is it possible that the government picked the worst possible options and escalated the situation to irreversible? . | At what cost people are willing to pay for what they disagree on? It is naive to deny/justify the violence that happened. The issue is after you have tried all the possible peaceful means and got no response, it is encouraging people to go to extremes, especially if they are not the minority. People always talk about the events since 2019 July but they don’t discuss why the government gave no response after a peaceful protest with 2 millions+ [aka around 1/3 of the city population]. . | In my view, this is removing the brake from the movement because the peaceful supporters cannot propose another way but sit back. When did the stupid government ask why do you not condemn the violence? The answer is simple: it was you who told us peaceful marches did not work, it was you who removed the brake when we asked you not to. . | Who should be responsible? Well……it is like……someone turns on the lighter and burns the house, will you blame why the house is flammable when everyone asks you not to? It is sad that hundreds if not thousands of protestors may be in jail at last for the disaster that could be avoided from the beginning. . | I don’t hold any particular “political beliefs”, I don’t like the bundle package because the narrative makes us give up our rational thinking. As long as we are solving the problems but not solving the people who raise the problems, any idea should be evaluated to considered and evaluated. . | .",
          "url": "https://g-hung.github.io/blog/books/",
          "relUrl": "/books/",
          "date": ""
      }
      
  

  

  
      ,"page4": {
          "title": "Projects",
          "content": "Project ARK . Feb 2021 . . A automataed data pipeline to scrape &amp; store daily ARK holdings data using GitHub Actions, BigQuery, command line, Python and dbt. Collect the fund weight data to further study the trading strategy and signals . .",
          "url": "https://g-hung.github.io/blog/projects/",
          "relUrl": "/projects/",
          "date": ""
      }
      
  

  
  

  
  

  

  
  

  
  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://g-hung.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}